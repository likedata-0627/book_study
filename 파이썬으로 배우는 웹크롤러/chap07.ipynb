{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-1  lxml 파서 1)\n",
    ">* c언어로 구현되었기 때문에 가장 빠름\n",
    ">* xml처리도 가능하지만 c언어로 구현되었기 때문에 c언어 의존적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><p>test</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''<p>test</p>'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-2 lxml 파서 2)\n",
    ">* lxml은 html과 body 태그가 포함된 형태로 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><p>test</p></body></html>\n",
      "<html><body><p>test</p></body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''<p>test</p>'''\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup)\n",
    "\n",
    "html = '''<body><p>test</p></body>'''\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-3 html5lib 파서 \n",
    ">* 내꺼는 3.x 대라 일단 실행안됨. 이거 참고하고 보자\n",
    ">* 웹 브라우저 형태로 html을 분석하고 관리, 파이썬으로 구현되어 있기 때문에 c언어에 의존적이지는 않나, 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-be2be2dde4d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'''<p>test</p>'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\study\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                     % \",\".join(features))\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;31m# At this point either we have a TreeBuilder instance in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "\n",
    "html = '''<p>test</p>'''\n",
    "\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-4 html5lib 파서 2)\n",
    ">* html 처럼 해석을 하기 때문에 html, head, body 태그가 포함된 형태로 만들어 줌\n",
    ">* html, head, body 태그가 하나라도 없다면 해당 태그를 추가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-27eee39bf0af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'''<html><body><p>test</p></body></html>'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\study\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                     % \",\".join(features))\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;31m# At this point either we have a TreeBuilder instance in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "\n",
    "html = '''<html><body><p>test</p></body></html>'''\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "print(soup)\n",
    "\n",
    "html = '''<html><head></head><p>test</p></html>'''\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "print(soup)\n",
    "\n",
    "html = '''<head><p>test</p></head>'''\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-5 프로그램 시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "측정하고 싶은 실행 코드\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "print('측정하고 싶은 실행 코드')\n",
    "\n",
    "endTime = time.time() - startTime\n",
    "print(endTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-6 lxml vs html5lib 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-79e40bcc5ca5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mBeautifulSoup\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mhtml5lib_end_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mstartTime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\study\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                     % \",\".join(features))\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;31m# At this point either we have a TreeBuilder instance in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''<html><head></head><p>test</p></html>'''\n",
    "\n",
    "startTime = time.time()\n",
    "BeautifulSoup (html, 'lxml')\n",
    "lxml_end_time = time.time() -startTime\n",
    "\n",
    "startTime = time.time()\n",
    "BeautifulSoup (html, 'html5lib')\n",
    "html5lib_end_time = time.time() -startTime\n",
    "\n",
    "print('lxml 시간측정 : %f'%(lxml_end_time))\n",
    "print('html5lib 시간측정 : %f'%(html5lib_end_time))\n",
    "print(html5lib_end_time/ lxml_end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-7 lxml vs html5lib 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-cfe080ecb3fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mBeautifulSoup\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mhtml5lib_end_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mstartTime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\study\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                     % \",\".join(features))\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;31m# At this point either we have a TreeBuilder instance in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''<html><head></head><p>test</p></html>'''\n",
    "\n",
    "time_sum = 0\n",
    "loop_count = 5\n",
    "for i in range(0, loop_count):\n",
    "    \n",
    "    startTime = time.time()\n",
    "    BeautifulSoup (html, 'lxml')\n",
    "    lxml_end_time = time.time() -startTime\n",
    "\n",
    "    startTime = time.time()\n",
    "    BeautifulSoup (html, 'html5lib')\n",
    "    html5lib_end_time = time.time() -startTime\n",
    "    \n",
    "    rate = html5lib_end_time/ lxml_end_time\n",
    "\n",
    "    print('%d 번째 시도'%(i))\n",
    "    print('lxml 시간측정 : %f' %(lxml_end_time))\n",
    "    print('html5lib 시간측정 : %f' %(html5lib_end_time))\n",
    "    print('**', rate, '**\\n')\n",
    "    time_sum += rate\n",
    "    \n",
    "average = time_sum / loop_count\n",
    "print('평균속도 : %f' %(average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-8 파서를 잘못 넣을 경우 \n",
    ">* 에러 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: test. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-68b4f4fed8c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtime_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\study\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                     % \",\".join(features))\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;31m# At this point either we have a TreeBuilder instance in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: test. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"<html><head></head><p>test</p></html>\"\"\"\n",
    "\n",
    "time_sum = 0\n",
    "BeautifulSoup(html, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-9 bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><p>test</p></body></html>\n",
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head> </head> <body> <p>test</p> </body> </html>\"\"\"\n",
    "\n",
    "BeautifulSoup(html, 'lxml')\n",
    "print(soup)\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-10 html을 예쁘게 출력 \n",
    ">* prettify() 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <p>\n",
      "   test\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head> <title>test site</title></head> <body> <p>test</p> <p>test1</p> <p>test2</p> </body> </html>\"\"\"\n",
    "\n",
    "BeautifulSoup(html, 'lxml')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-11 태그 접근\n",
    ">* soup.[태그 이름} 의 형태로 정보 가져 올 수 있음 => 하지만 이경우는 가장 첫번째로 등장하는 태그의 정보만 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>test site</title>\n",
      "<class 'bs4.BeautifulSoup'> , <class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head> <title>test site</title></head> <body> <p>test</p> <p>test1</p> <p>test2</p> </body> </html>\"\"\"\n",
    "\n",
    "soup=BeautifulSoup(html, 'lxml')\n",
    "tag_title = soup.title\n",
    "\n",
    "print(tag_title)\n",
    "print(type(soup), ',', type(tag_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-12 태그 데이터 뽑기\n",
    ">* text 속성과 string 속성을 이용하면 태그의 값을 가져올 수 있음\n",
    ">* 그리고 결과는 같아 보이나, 약간의 차이는 있음\n",
    ">* name 속성을 이용하면 태그이름을 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test site\n",
      "test site\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head> <title>test site</title></head> <body> <p>test</p> <p>test1</p> <p>test2</p> </body> </html>\"\"\"\n",
    "\n",
    "soup=BeautifulSoup(html, 'lxml')\n",
    "tag_title = soup.title\n",
    "\n",
    "print(tag_title.text)\n",
    "print(tag_title.string)\n",
    "print(tag_title.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-13 태그에서 속성 뽑기\n",
    ">* a태그의 href속성, img태그의src 속성을 가져오기 위해서는 속성에 접근을 해야함\n",
    ">* 태그에서 attrs 속성을 이용하면 해당 태그의 속성을 가져올 수 있음\n",
    ">* 그리고 태그의 속성에 접근 할 때 딕셔너리에서 [키:값]의 형태를 접근하는 것 처럼 하면 됨. \n",
    ">* 키값이 없으면 에러 발생\n",
    ">* 이를 방지하기 위해서 get() 함수를 이용하면 키가 존재하지 않을때 기본값을 설정 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['t'], 'id': 'ti'}\n",
      "['t']\n",
      "ti\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html =  \"\"\"<html> <head><title class=\"t\" id=\"ti\">test site</title></head> <body> <p>test</p> <p>test1</p> <p>test2</p> </body></html>\"\"\"\n",
    "soup=BeautifulSoup(html, 'lxml')\n",
    "tag_title = soup.title\n",
    "\n",
    "print(tag_title.attrs)\n",
    "print(tag_title['class'])\n",
    "print(tag_title['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-14 태그에 없는 속성 접근\n",
    ">* 존재하지 않은 속성값에 접근하면, 딕셔너리에서 없는 키에 접근했을 때 발생하는 keyerror가 발생 \n",
    ">* get()을 이용해서 속성에 접근하면 에러를 방지할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-63942dbf1470>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtag_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\study\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\n\u001b[0;32m   1320\u001b[0m         and throws an exception if it's not there.\"\"\"\n\u001b[1;32m-> 1321\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class1'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title class=\"t\" id=\"ti\">test site</title></head> <body> <p>test</p> <p>test1</p> <p>test2</p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "tag_title = soup.title\n",
    "\n",
    "print(tag_title['class1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-15 get 이용 속성 접근\n",
    "> * 존재하지 않는 속성값으로 인한 에러를 방지 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['t'], 'id': 'ti'}\n",
      "['t']\n",
      "ti\n",
      "None\n",
      "default_value\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title class=\"t\" id=\"ti\">test site</title></head> <body> <p>test</p> <p>test1</p> <p>test2</p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "tag_title = soup.title\n",
    "\n",
    "print(tag_title.attrs)\n",
    "print(tag_title.get('class'))\n",
    "print(tag_title.get('id'))\n",
    "print(tag_title.get('class1'))\n",
    "print(tag_title.get('class1', 'default_value'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-16 태그의 text와 string 속성 차이\n",
    ">* 이 둘은 타입이 다름 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  test site <class 'str'>\n",
      "string :  test site <class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title class=\"t\" id=\"ti\">test site</title></head> <body> <p>test</p> <p>test1</p> <p>test2</p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "tag_title = soup.title\n",
    "\n",
    "data_text = tag_title.text\n",
    "data_string = tag_title.string\n",
    "\n",
    "print('text : ', data_text, type(data_text))\n",
    "print('string : ', data_string, type(data_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-17 복잡한 태그에서 text와 string 속성 차이\n",
    ">* text는 하위 태그에 대한 값들도 전부 출력\n",
    ">* string은 정확히 태그에 대한 값만 출력\n",
    ">* tag_p.span.string 처럼 자식태그가 존재하지 않는 태그까지접근해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  test <class 'str'>\n",
      "string :  test <class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test</p> <p>test1</p> <p>test2</p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "tag_p = soup.p\n",
    "\n",
    "data_text = tag_p.text\n",
    "data_string = tag_p.string\n",
    "\n",
    "print('text : ', data_text, type(data_text))\n",
    "print('string : ', data_string, type(data_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-18 content 활용하여 자식 태그 가져오기\n",
    ">* contents 속성을 사용하면 리스트 형태로 자식 태그를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span>test1</span>, <span>test2</span>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_p_contents = soup.p.contents\n",
    "\n",
    "print(tag_p_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-19 children 활용하여 자식 태그 가져오기 1)\n",
    ">* children은 <이터레이터 object> 형태로 반환\n",
    ">* children으로 가져온 값은 반복문을 이용해 사용해야 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<list_iterator object at 0x00000152A8E56608>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_p_children = soup.p.children\n",
    "\n",
    "print(tag_p_children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-20 children 활용하여 자식 태그 가져오기 2)\n",
    ">* 반복문을 이용하여 p의 자식 태그인 span을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span>test1</span>\n",
      "<span>test2</span>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_p_child = soup.p.children\n",
    "\n",
    "for child in tag_p_child:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-21 부모 태그 접근하기 parent\n",
    ">* 부모 태그로 올라가는 형태로 접근이 가능\n",
    ">* 예를 들어 title태그로 head 태그 접근, span 태그로 p태그 접근하는 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태그\n",
      "<span>test1</span>\n",
      "<title>test site</title>\n",
      "부모태그\n",
      "<p><span>test1</span><span>test2</span></p>\n",
      "<head><title>test site</title></head>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_span = soup.span\n",
    "tag_title = soup.title\n",
    "\n",
    "span_parent = tag_span.parent\n",
    "title_parent = tag_title.parent\n",
    "\n",
    "print('태그')\n",
    "print(tag_span)\n",
    "print(tag_title)\n",
    "\n",
    "print('부모태그')\n",
    "print(span_parent)\n",
    "print(title_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-22 부모 태그 접근하기 parents 1)\n",
    ">* <제너레이터 객체>의 형태로 가져옴\n",
    ">* 반복문을 이용하면 결과를 확인 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태그\n",
      "<span>test1</span>\n",
      "<title>test site</title>\n",
      "부모태그\n",
      "<generator object PageElement.parents at 0x00000152A4E4AB48>\n",
      "<generator object PageElement.parents at 0x00000152A8589C48>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_span = soup.span\n",
    "tag_title = soup.title\n",
    "\n",
    "span_parents = tag_span.parents\n",
    "title_parents = tag_title.parents\n",
    "\n",
    "print('태그')\n",
    "print(tag_span)\n",
    "print(tag_title)\n",
    "\n",
    "print('부모태그')\n",
    "print(span_parents)\n",
    "print(title_parents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-23 부모 태그 접근하기 parents 2)\n",
    ">* parents 속성을 이용하면 가장 최상위 부모 태그 까지 가져올 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태그\n",
      "<span>test1</span>\n",
      "<title>test site</title>\n",
      "부모태그\n",
      "<p><span>test1</span><span>test2</span></p>\n",
      "<body> <p><span>test1</span><span>test2</span></p> </body>\n",
      "<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\n",
      "<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\n",
      "title 부모태그\n",
      "<head><title>test site</title></head>\n",
      "<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\n",
      "<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_span = soup.span\n",
    "tag_title = soup.title\n",
    "\n",
    "span_parents = tag_span.parents\n",
    "title_parents = tag_title.parents\n",
    "\n",
    "print('태그')\n",
    "print(tag_span)\n",
    "print(tag_title)\n",
    "\n",
    "print('부모태그')\n",
    "for parent in span_parents:\n",
    "    print(parent)\n",
    "    \n",
    "print('title 부모태그')\n",
    "for parent in title_parents:\n",
    "    print(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-24 형제 태그 접근 1)\n",
    ">*  형제 태그란 동등한 위치의 태그를 의미\n",
    ">* p태그 아래에 있는 두 개의 span 태그는 서로 형제 관계 라고 할 수 있음. \n",
    ">* next_sibling 과  prev_sibling으로 다음형제와 이전 형제를 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span>test2</span>\n",
      "<span>test1</span>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_span = soup.span\n",
    "\n",
    "a = tag_span.next_sibling\n",
    "b = a.previous_sibling\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-25 형제 태그 접근 2)\n",
    ">* 가장 먼저 등장하는 형제느 prev_sibling 속성을 가져오면 none 값 나옴 => 이전에 등장하는 형제가 없으므로\n",
    ">* 가장 마지막에 등장하는 형제도 next_sibling 속성을 가져오면 none => 다음에 등장하는 형제도 없기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags\n",
      "<a>test1</a>\n",
      "<b>test2</b>\n",
      "<c>test3</c>\n",
      "sibling\n",
      "<b>test2</b>\n",
      "None\n",
      "<c>test3</c>\n",
      "<a>test1</a>\n",
      "None\n",
      "<b>test2</b>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html =\"\"\"<html> <head><title>test site</title></head> <body> <p><a>test1</a><b>test2</b><c>test3</c></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_a = soup.a\n",
    "tag_b = soup.b\n",
    "tag_c = soup.c\n",
    "\n",
    "print('tags')\n",
    "print(tag_a)\n",
    "print(tag_b)\n",
    "print(tag_c)\n",
    "\n",
    "tag_a_next = tag_a.next_sibling\n",
    "tag_a_prev = tag_a.previous_sibling\n",
    "\n",
    "tag_b_next = tag_b.next_sibling\n",
    "tag_b_prev = tag_b.previous_sibling\n",
    "\n",
    "tag_c_next = tag_c.next_sibling\n",
    "tag_c_prev = tag_c.previous_sibling\n",
    "\n",
    "print('sibling')\n",
    "print(tag_a_next)\n",
    "print(tag_a_prev)\n",
    "\n",
    "print(tag_b_next)\n",
    "print(tag_b_prev)\n",
    "\n",
    "print(tag_c_next)\n",
    "print(tag_c_prev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-26 형제 태그 접근 3)\n",
    ">* next_siblings, previous_siblings 로 사용이 가능 => <제너레이터 객체> 로 반환되므로 반복문을 이용하여 출력 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags\n",
      "<a>test1</a>\n",
      "<b>test2</b>\n",
      "<c>test3</c>\n",
      "<generator object PageElement.next_siblings at 0x00000152AADB76C8>\n",
      "<generator object PageElement.previous_siblings at 0x00000152A99A6CC8>\n",
      "next siblings\n",
      "<b>test2</b>\n",
      "<c>test3</c>\n",
      "previous siblings\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html =\"\"\"<html> <head><title>test site</title></head> <body> <p><a>test1</a><b>test2</b><c>test3</c></p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_a = soup.a\n",
    "tag_b = soup.b\n",
    "tag_c = soup.c\n",
    "\n",
    "print('tags')\n",
    "print(tag_a)\n",
    "print(tag_b)\n",
    "print(tag_c)\n",
    "\n",
    "tag_a_nexts = tag_a.next_siblings\n",
    "tag_a_prevs = tag_a.previous_siblings\n",
    "\n",
    "print(tag_a_nexts)\n",
    "print(tag_a_prevs)\n",
    "\n",
    "print('next siblings')\n",
    "for sibling in tag_a_nexts:\n",
    "    print(sibling)\n",
    "\n",
    "print('previous siblings')\n",
    "for sibling in tag_a_prevs:\n",
    "    print(sibling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-27 요소 접근하기 1)\n",
    ">* 요소란 태그, 태그안에 들어있는 자식태크 , 문자도 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1\n",
      "<b>test2</b>\n",
      "test2\n",
      "<c>test3</c>\n",
      "test3\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><a>test1</a><b>test2</b><c>test3</c></p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_a = soup.a\n",
    "tag_a_nexts = tag_a.next_elements\n",
    "\n",
    "for i in tag_a_nexts:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-28 요소 접근하기 2)\n",
    ">* next_elements, prev_elements 를 이용하여 이전요소, 다음요소로 접근 가능\n",
    ">* 이때, 태그의 다음 요소는 ~형제태그~ 가 아닌 자식태그를 먼저 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   test site\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   <a>\n",
      "    test1\n",
      "   </a>\n",
      "   <b>\n",
      "    test2\n",
      "   </b>\n",
      "   <c>\n",
      "    test3\n",
      "   </c>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "***elements***\n",
      "<a>test1</a>\n",
      "test1\n",
      "<b>test2</b>\n",
      "test2\n",
      "<c>test3</c>\n",
      "test3\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><a>test1</a><b>test2</b><c>test3</c></p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_p_nexts = soup.p.next_elements\n",
    "\n",
    "print(soup.prettify())\n",
    "print('***elements***')\n",
    "\n",
    "for i in tag_p_nexts:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-29 타입 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a>ttt<span>123</span><span>123</span></a> False True\n",
      "ttt True False\n",
      "<span>123</span> False True\n",
      "123 True False\n",
      "<span>123</span> False True\n",
      "123 True False\n",
      "<b>test2</b> False True\n",
      "test2 True False\n",
      "<c>test3</c> False True\n",
      "test3 True False\n",
      "  True False\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><a>ttt<span>123</span><span>123</span></a><b>test2</b><c>test3</c></p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_p_nexts = soup.p.next_elements\n",
    "\n",
    "for i in tag_p_nexts:\n",
    "    print(i, type(i) == NavigableString, type(i) == Tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-30 원하는 태그 전부 가져오기\n",
    ">* find_all() 함수를 이용하면 우리가 원하는 태그들의 리스트의 형태로 얻어 올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>test site</title>]\n",
      "[<p>test1</p>, <p>test2</p>, <p>test3</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p>test2</p><p>test3</p></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all('title'))\n",
    "print(soup.find_all('p'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-31 id 값으로 가져오기\n",
    ">* id=''를 이용하여 원하는 id값을 가진 태그를 가져 올 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"d\">test2</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p id=\"d\">test2</p><p>test3</p></p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all(id='d'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-32 id 존재 유무로 가져오기\n",
    ">* id = True는 id가 존재하는 태그 를 리스트로 가져옴\n",
    ">* id = False는 id가 존재하지 않는 태그 를 리스트로 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"d\">test2</p>]\n",
      "[<p>test1</p>, <p>test3</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p id=\"d\">test2</p><p>test3</p></p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all(id=True))\n",
    "print(soup.body.find_all(id=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-33 원하는 태그, 원하는 id 값으로 태그 가져오기\n",
    ">* id가 d 인 p태그, id가 c인 p태그를 찾는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"d\">test2</p>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p id=\"d\">test2</p><p>test3</p></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all('p', id='d'))\n",
    "print(soup.find_all('p', id='c'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-34 class 속성 이용하여 필요한 태그 가져오기 1)\n",
    ">* class를 이용해 태그를 가져오고 싶다면 class_로 표현을 해줘야 햠\n",
    ">* class라는 키워드는 클래스를 만들대 사용하는 키워드 임으로 언더바를 붙여 중복을 피할것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"d\">test2</p>]\n",
      "[<p class=\"c\">test3</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all('p', class_='d'))\n",
    "print(soup.find_all('p', class_='c'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-35 class 속성 이용하여 필요한 태그 가져오기 2)\n",
    ">* 클래스 속성은 굳이 class_ 키워드를 사용하지 않아도 됨\n",
    ">* id, class 뿐 아니라 태그에 들어 있는 속성명을 사용할 수 있는데, a 태그의 href, img 태그의 src 등이 있음\n",
    ">* name을 이용하면 택의 값으로 태그를 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"d\">test2</p>]\n",
      "[<p class=\"c\">test3</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> </body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all('p', 'd'))\n",
    "print(soup.find_all('p', 'c'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-36 text 속성을 이용해 필요한 태그를 가져오기\n",
    ">* p 태그 중에서 'test1' 이라느 ㄴ값을 가진 태그와 't'라는 값을 가진 태그를 찾는 코드, text는 값을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>test1</p>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all('p', text= 'test1'))\n",
    "print(soup.find_all('p', text= 't'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-37 limit 키워드 이용하여 가져오는 태그 제한하기\n",
    ">* find_all() 을 이용할 때 태그의 양을 제한해 주어야 할 때가 있을 때 limit를 사용\n",
    "> limit 값이 해당 태그의 양보다 많아도 에러는 띄우지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>test1</p>]\n",
      "[<p>test1</p>, <p class=\"d\">test2</p>]\n",
      "[<p>test1</p>, <p class=\"d\">test2</p>, <p class=\"c\">test3</p>]\n",
      "[<p>test1</p>, <p class=\"d\">test2</p>, <p class=\"c\">test3</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all('p', limit= 1))\n",
    "print(soup.find_all('p', limit= 2))\n",
    "print(soup.find_all('p', limit= 3))\n",
    "print(soup.find_all('p', limit= 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-38 find_all() 빈 인자로 모든 태그 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p> </body></html>, <head><title>test site</title></head>, <title>test site</title>, <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p> </body>, <p>test1</p>, <p class=\"d\">test2</p>, <p class=\"c\">test3</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-39 여러 태그 가져오기\n",
    ">* find_all()을 사용할 때 리스트 형태로 인자를 주면 여러개의 태그를 가져올 수 있음\n",
    ">* find_all() 함수에 가져오고 싶은 태그를 리스트로 만들어 넘기면 원하는 태그를 전부 가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a>a tag</a>, <b>b tag</b>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all(['a','b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-40 find_all() 연속적으로 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'> [<body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p> <a>a tag</a> <b>b tag</b></body>]\n",
      "<class 'bs4.element.ResultSet'> [<p>test1</p>, <p class=\"d\">test2</p>, <p class=\"c\">test3</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "tag_body = soup.find_all('body')\n",
    "tag_p = tag_body[0].find_all('p')\n",
    "\n",
    "print(type(tag_body), tag_body)\n",
    "print(type(tag_p), tag_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-41 find() 와 find_all() 비교하기 1)\n",
    ">* find() 는 해당 페이지에서 찾고자 하는 요소가 하나만 있을 때 사용\n",
    ">* 가장 많이 사용 되는 예가 id 값으로 접근하는 요소\n",
    ">* 하나의 요소만 접근하고자 할때는 find()를 사용하는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>test1</p>\n",
      "<p>test1</p>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find('p'))\n",
    "print(soup.find_all('p', limit=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-42 find() 와 find_all() 비교하기 2)\n",
    ">* find_all()에서 에러가 발생하는데,[]가 반환되고 여기서 0번쨰 인덱스 접근을 하므로 indexError가 발생\n",
    ">* 반면에 find()는 해당요소가 없으면 None 값을 반환\n",
    ">* find()의 사용법은 find_all()과 다르지 않음, 단지 find_all은 리스트로 find()는 요소로 반환한다는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-54e88c905403>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p>test1</p><p class=\"d\">test2</p><p class=\"c\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find('img'))\n",
    "print(soup.find_all('img', limit=1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-43  find() 를 사용하기\n",
    ">* 찾으려는 대상이 문서에 하나만 존재한다면 find_all()을 사용하는 것보다 편하게 사용\n",
    ">* 고유한 값을 가져야 한다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"d\">test2</p>\n",
      "<p class=\"d\">test2</p>\n",
      "<p class=\"a\" id=\"i\">test1</p>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p><p class=\"d\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find('p', class_='d'))\n",
    "print(soup.find('p', class_='d'))\n",
    "print(soup.find('p', id='i'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-44  연속적인 find() 를 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"d\">test2</p>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p><p class=\"d\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find('body').find('p', class_='d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-45 select() 사용하기\n",
    ">* find_all() 처럼 리스트로 반환됨\n",
    ">* 하지만 다른 점은 css 셀렉터를 활용하여 원하는 요소에 접근한다는 점이다\n",
    ">* 모든 결과를 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"a\" id=\"i\">test1</p>, <p class=\"d\">test2</p>, <p class=\"d\">test3</p>]\n",
      "[<p class=\"d\">test2</p>, <p class=\"d\">test3</p>]\n",
      "[<p class=\"d\">test2</p>, <p class=\"d\">test3</p>]\n",
      "[<p class=\"a\" id=\"i\">test1</p>]\n",
      "[<p class=\"a\" id=\"i\">test1</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p><p class=\"d\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.select('p'))\n",
    "print(soup.select('.d'))\n",
    "print(soup.select('p.d'))\n",
    "print(soup.select('#i'))\n",
    "print(soup.select('p#i'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-46 연속적인 접근\n",
    ">* 여기서 ***클래스는 마침표 (.), 아이디는 샵(#)***으로 접근하는 것만 알면 셀렉터를 만들수 있음\n",
    ">* 마지막으로 ***자식 태그를 표현할 때 띄어 쓰기***를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"a\" id=\"i\">test1</p>, <p class=\"d\">test2</p>, <p class=\"d\">test3</p>]\n",
      "[<p class=\"d\">test2</p>, <p class=\"d\">test3</p>]\n",
      "[<p class=\"d\">test2</p>, <p class=\"d\">test3</p>]\n",
      "[<p class=\"a\" id=\"i\">test1</p>]\n",
      "[<p class=\"a\" id=\"i\">test1</p>]\n",
      "[<p class=\"a\" id=\"i\">test1</p>, <p class=\"d\">test2</p>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <div><p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.select('body p'))\n",
    "print(soup.select('body .d'))\n",
    "print(soup.select('body p.d'))\n",
    "print(soup.select('body #i'))\n",
    "print(soup.select('body p#i'))\n",
    "\n",
    "print(soup.select('div p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-47 필요없는 태그 제거 1)\n",
    ">* extract() 는 테그를 지우는 역할을 함\n",
    ">* 실제 웹 사이트에서 html을 가져오면 용량이 크기 때문에 style, script같이 크롤링하는데 필요 없는 태그는 제거해서 사용이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거항목\n",
      "<body> <div><p class=\"a\" id=\"i\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p> <a>a tag</a> <b>b tag</b></body>\n",
      "제거완료\n",
      "<html> <head><title>test site</title></head> </html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <div><p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "a = soup.body.extract()\n",
    "\n",
    "print('제거항목')\n",
    "print(a)\n",
    "print('제거완료')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-48 필요없는 태그 제거 2)\n",
    ">* find_all(), find(), select() 를 이용하여 요소에 접근한 후 extract()를 이용하여 해당 태그를 제거 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"a\" id=\"i\">test1</p>\n",
      "<p class=\"d\">test2</p>\n",
      "<p class=\"d\">test3</p>\n",
      "제거완료\n",
      "<html> <head><title>test site</title></head> <body> <div></div> <a>a tag</a> <b>b tag</b></body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <div><p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "for tag in soup.select('p'):\n",
    "    print(tag.extract())\n",
    "    \n",
    "print('제거완료')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-49 필요없는 태그 제거 3)\n",
    ">* 특히 find_all을 이용하면 여러개의 태그를 한번에 제거 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"a\" id=\"i\">test1</p>\n",
      "<p class=\"d\">test2</p>\n",
      "<p class=\"d\">test3</p>\n",
      "<a>a tag</a>\n",
      "제거완료\n",
      "<html> <head><title>test site</title></head> <body> <div></div>  <b>b tag</b></body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <div><p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "for tag in soup.find_all(['p','a']):\n",
    "    print(tag.extract())\n",
    "    \n",
    "print('제거완료')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-50 필요 없는 태그 제거 함수\n",
    ">* 첫번째 인자는 soup을 받고 두번째 인자는 없애고 싶은 태그를 받음\n",
    ">* 두번째 인자는 리스트와 문자열 두가지 타입을 모두 받을 수 있음\n",
    ">* 빈 리스트 []가 들어갈 경우 모든 태그를 없애기 때문에 [] 빈리스트를 받게 되면 함수를 즉시 종료 시킴\n",
    ">* 빈 값은 사용자의 실수가 있을 수 있기 때문에 실수의 가능성의 있는 부분은 자체적으로 처리 해 주었음\n",
    ">* 마지막으로 해당 함수는 제거된 태그 요소를 리스트로 만들어 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<html> <head><title>test site</title></head> <body> <div><p class=\"a\" id=\"i\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p> <a>a tag</a> <b>b tag</b></body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_tag(soup, tags):\n",
    "    if tags == []:\n",
    "        return False\n",
    "    \n",
    "    removes = []\n",
    "    \n",
    "    for tag in soup.find_all(tags):\n",
    "        remove.append(tag.extract())\n",
    "        \n",
    "    return removes\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <div><p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p></p> <a>a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "removed_tag = remove_tag(soup, [])\n",
    "print(removed_tag)\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-51 정규식을 사용하기 위해 re모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-52 find_all() 과 re조합\n",
    ">* re.compilr()을 이용하여 해당 문자열이 포함된 요소를 찾는 코드\n",
    ">* re.compile()은 검색, 치환하고자 하는 패턴을 만드는 함수\n",
    ">* 정규식을 이용하면 정확한 단어가 아니라 특정단어를 포함하고, 패턴이 일치하는 요소를 찾을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"d\">test2</p>, <p class=\"d\">test3</p>]\n",
      "[<p class=\"a\" id=\"i\">test1</p>]\n",
      "[<html> <head><title>test site</title></head> <body> <div><p class=\"a\" id=\"i\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p> <a href=\"/example/test1\">a tag</a> <b>b tag</b></body></html>, <title>test site</title>]\n",
      "[<title>test site</title>]\n",
      "[<a href=\"/example/test1\">a tag</a>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <div><p id=\"i\" class=\"a\">test1</p><p class=\"d\">test2</p></div><p class=\"d\">test3</p></p> <a href=\"/example/test1\">a tag</a> <b>b tag</b></body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "print(soup.find_all(class_=re.compile('d'))) # 클래스 값에  d가 포함된 요소를 찾기\n",
    "print(soup.find_all(id=re.compile('i'))) # 아이디 값에 i가 포함된 요소를 찾기\n",
    "print(soup.find_all(re.compile('t'))) # 태그에 t가 포함된 요소를 찾ㄱ\n",
    "print(soup.find_all(re.compile('^t'))) # 태그 이름이 t로 시작하는 요소를 찾기 (^는 시작을 의미)\n",
    "print(soup.find_all(href=re.compile('/'))) # href에 슬래시(/)가 포함된 요소를 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-53 정규 표현식 사용\n",
    ">* 정규식은 우리가 문자열을 다룰때 문자열에서 특정 패턴을 검색거나 바꾸기 위해 사용하는 식\n",
    ">* 파이썬에서는 정규식을 사용하기 위해 re모듈을 사용\n",
    ">* 정규식을 만들기 위해서는 3가지 과정을 거칩니다. \n",
    ">* 1) 패턴만들기: re.compile(정규표현식)을 이용하여 패턴을 만들기\n",
    ">* 2) 만들어진 패턴을 이용해서 match(문자열), search(문자열), findall(문자열), finditer(문자열)을 만듬\n",
    ">* 3) 2단계에서 match(). search()를 통해 나온 결과물을 group(), start(), end(), span()을 이용하여 리턴, findall()과 finditer()은 리스트와 객체로 반환하므로 반복문을 이용하여 group(), start(), end(), span()를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- match result --\n",
      "<re.Match object; span=(0, 4), match='test'>\n",
      "test 0 4 (0, 4)\n",
      "-- search result --\n",
      "<re.Match object; span=(0, 4), match='test'>\n",
      "test 0 4 (0, 4)\n",
      "-- findall result --\n",
      "['test', 'test']\n",
      "-- finditer result --\n",
      "<callable_iterator object at 0x00000152A4AEC8C8>\n",
      "test 0 4 (0, 4)\n",
      "test 12 16 (12, 16)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "test_str = 'test t1sd j test1'\n",
    "\n",
    "pattern = re.compile('test')\n",
    "a = pattern.match(test_str)\n",
    "b = pattern.search(test_str)\n",
    "c = pattern.findall(test_str)\n",
    "d = pattern.finditer(test_str)\n",
    "\n",
    "print('-- match result --')\n",
    "print(a)\n",
    "print(a.group(), a.start(), a.end(), a.span())\n",
    "\n",
    "print('-- search result --')\n",
    "print(b)\n",
    "print(b.group(), b.start(), b.end(), b.span())\n",
    "\n",
    "print('-- findall result --')\n",
    "print(c)\n",
    "\n",
    "print('-- finditer result --')\n",
    "print(d)\n",
    "for i in d:\n",
    "    print(i.group(), i.start(), i.end(), i.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-54 숫자찾기\n",
    ">* [0-9]는 0부터 9를 의미\n",
    ">* +는 하나이상 포함 된것을 계속 찾아 줌\n",
    ">* 즉 [0-9]+ 는 0부터 9까지 포함되면 하나의 값으로 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '5', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '1', '2', '3', '4', '5', '9', '8', '7', '3', '1', '4', '1', '6', '1', '8', '0', '9', '0', '0', '0', '4', '2']\n",
      "['25', '0123456789', '12345', '98', '7', '3', '141', '6180', '9', '000', '42']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test_str= \"\"\"I am Park Jeong-tae. I live in Paju.\n",
    "I lived in Paju for 25 years.\n",
    "Sample text for testing:\n",
    "abcdefghijklmnopqrsAvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "0123456789 _+-.,!@#$%^&*();\\/|<>\"'\n",
    "12345 -98.7 3.141 .6180 9,000 +42\"\"\"\n",
    "\n",
    "pattern = re.compile('[0-9]')\n",
    "pattern1 = re.compile('[0-9]+')\n",
    "c = pattern.findall(test_str)\n",
    "d = pattern1.findall(test_str)\n",
    "\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-55 대문자, 소문자 찾기\n",
    ">* [a-z]는 a부터 z까지\n",
    ">* [A-Z]는 A부터 Z까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'm', 'a', 'r', 'k', 'e', 'o', 'n', 'g', 't', 'a', 'e', 'l', 'i', 'v', 'e', 'i', 'n', 'a', 'j', 'u', 'l', 'i', 'v', 'e', 'd', 'i', 'n', 'a', 'j', 'u', 'f', 'o', 'r', 'y', 'e', 'a', 'r', 's', 'a', 'm', 'p', 'l', 'e', 't', 'e', 'x', 't', 'f', 'o', 'r', 't', 'e', 's', 't', 'i', 'n', 'g', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 'v', 'w', 'x', 'y', 'z']\n",
      "['am', 'ark', 'eong', 'tae', 'live', 'in', 'aju', 'lived', 'in', 'aju', 'for', 'years', 'ample', 'text', 'for', 'testing', 'abcdefghijklmnopqrs', 'vwxyz']\n",
      "['I', 'P', 'J', 'I', 'P', 'I', 'P', 'S', 'A', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "['I', 'P', 'J', 'I', 'P', 'I', 'P', 'S', 'A', 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test_str= \"\"\"I am Park Jeong-tae. I live in Paju.\n",
    "I lived in Paju for 25 years.\n",
    "Sample text for testing:\n",
    "abcdefghijklmnopqrsAvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "0123456789 _+-.,!@#$%^&*();\\/|<>\"'\n",
    "12345 -98.7 3.141 .6180 9,000 +42\"\"\"\n",
    "\n",
    "pattern = re.compile('[a-z]')\n",
    "pattern1 = re.compile('[a-z]+')\n",
    "c = pattern.findall(test_str)\n",
    "d = pattern1.findall(test_str)\n",
    "\n",
    "print(c)\n",
    "print(d)\n",
    "\n",
    "pattern = re.compile('[A-Z]')\n",
    "pattern1 = re.compile('[A-Z]+')\n",
    "c = pattern.findall(test_str)\n",
    "d = pattern1.findall(test_str)\n",
    "\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-56 대문자 + 소문자 찾기\n",
    ">* [a-zA-Z]는 a부터 z까지 A부터 Z까지 포함된 것을 모두 찾는 것을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'a', 'm', 'P', 'a', 'r', 'k', 'J', 'e', 'o', 'n', 'g', 't', 'a', 'e', 'I', 'l', 'i', 'v', 'e', 'i', 'n', 'P', 'a', 'j', 'u', 'I', 'l', 'i', 'v', 'e', 'd', 'i', 'n', 'P', 'a', 'j', 'u', 'f', 'o', 'r', 'y', 'e', 'a', 'r', 's', 'S', 'a', 'm', 'p', 'l', 'e', 't', 'e', 'x', 't', 'f', 'o', 'r', 't', 'e', 's', 't', 'i', 'n', 'g', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 'A', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "['I', 'am', 'Park', 'Jeong', 'tae', 'I', 'live', 'in', 'Paju', 'I', 'lived', 'in', 'Paju', 'for', 'years', 'Sample', 'text', 'for', 'testing', 'abcdefghijklmnopqrsAvwxyz', 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test_str= \"\"\"I am Park Jeong-tae. I live in Paju.\n",
    "I lived in Paju for 25 years.\n",
    "Sample text for testing:\n",
    "abcdefghijklmnopqrsAvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "0123456789 _+-.,!@#$%^&*();\\/|<>\"'\n",
    "12345 -98.7 3.141 .6180 9,000 +42\"\"\"\n",
    "\n",
    "pattern = re.compile('[a-zA-Z]')\n",
    "pattern1 = re.compile('[a-zA-Z]+')\n",
    "c = pattern.findall(test_str)\n",
    "d = pattern1.findall(test_str)\n",
    "\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-57 다양한 표현식\n",
    ">* +는 앞에 나온 패턴이 하나라도 일치하는 것을 찾고\n",
    ">* *는 앞에 나온 패턴이 하나라도 없어도 됨\n",
    ">* \\w는 문자, \\d는 숫자, \n",
    ">* {}는 반복 횟수\n",
    ">* \\w{3}는 문자를 3자리씩 묶어서 찾는것\n",
    ">* \\d{3}는 숫자를 3자리씩 묶어서 찾음\n",
    ">* [^a-z], [^A-Z]는 a부터 z까지 포함되지 않는 것, A부터 Z까지 포함되지 않는 것을 찾음\n",
    ">* ^는 시작이라는 의미인데, [] 대괄호 안에 있으면 포함하지 않는다는 것을 의미\n",
    ">* 마침표(.)을 이용하면 해당 자리를 표현 할수 있음. \n",
    ">* t. 이라고 하면 t로 시작하는 두 글자를 찾고, t..t는 t로 시작하고 t로 끝나는 4자리 문자열을 찾음\n",
    ">* t?est는 test나est를 찾는 패턴식으로 ?는 앞에 나온것이 있어도 되고 없어도 된다는 의미\n",
    ">* \\w는 문자를 의미하는데 +가 붙으면 test 또는 est 이후에 문자가 반드시 나와야 한다는 패턴을 찾음\n",
    ">* *가 붙으면 test 또는 est 이후에 문자가 반드시 있지 않아도 됨. \n",
    ">* 그렇기 떄문에 t?est\\w+는 test를 찾지 못하고 t?est\\w*는 test를 찾는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['010-6666-7777']\n",
      "['010-6666-7777']\n",
      "['010-6666-7777']\n",
      "['I', 'am', 'Park', 'Jeong', 'tae', 'I', 'live', 'in', 'Paju', 'I', 'lived', 'in', 'Paju', 'for', '25', 'years', 'estadsffjkfad', 'test', 'Sample', 'text', 'for', 'testing', 'abcdefghijklmestnopqrsAvwxyz', 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', '0123456789', '12345', '98', '7', '3', '141', '6180', '9', '000', '42']\n",
      "['I', 'am', 'Park', 'Jeong', 'tae', 'I', 'live', 'in', 'Paju', 'I', 'lived', 'in', 'Paju', 'for', '25', 'years', 'estadsffjkfad', 'test', 'Sample', 'text', 'for', 'testing', 'abcdefghijklmestnopqrsAvwxyz', 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', '0123456789', '12345', '98', '7', '3', '141', '6180', '9', '000', '42']\n",
      "['I ', ' P', ' J', '-', '. I ', ' ', ' P', '.\\nI ', ' ', ' P', ' ', ' 25 ', '. ', ' ', '\\nS', ' ', ' ', ' ', ':\\n', 'A', ' ABCDEFGHIJKLMNOPQRSTUVWXYZ\\n0123456789 +-.,!@#$%^&*();\\\\/|<>\"\\'\\n12345 -98.7 3.141 .6180 9,000 +42']\n",
      "[' am ', 'ark ', 'eong-tae. ', ' live in ', 'aju.\\n', ' lived in ', 'aju for 25 years. estadsffjkfad test\\n', 'ample text for testing:\\nabcdefghijklmestnopqrs', 'vwxyz ', '\\n0123456789 +-.,!@#$%^&*();\\\\/|<>\"\\'\\n12345 -98.7 3.141 .6180 9,000 +42']\n",
      "['test', 'text', 'test']\n",
      "[]\n",
      "['estadsffjkfad', 'testing', 'estnopqrsAvwxyz']\n",
      "['estadsffjkfad', 'test', 'testing', 'estnopqrsAvwxyz']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 전화번호 추출\n",
    "test_num = \"저의 전화번호는 010-6666-7777 입니다\"\n",
    "\n",
    "pattern = re.compile('[0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]')  #숫자숫자숫자-숫자숫자숫자숫자-숫자숫자숫자숫자 형태\n",
    "pattern1 = re.compile('\\d\\d\\d-\\d\\d\\d\\d-\\d\\d\\d\\d')  #숫자숫자숫자-숫자숫자숫자숫자-숫자숫자숫자숫자 형태\n",
    "pattern2 = re.compile('\\d{3}-\\d{4}-\\d{4}')  #숫자숫자숫자-숫자숫자숫자숫자-숫자숫자숫자숫자 형태\n",
    "c = pattern.findall(test_num)\n",
    "d = pattern1.findall(test_num)\n",
    "e = pattern2.findall(test_num)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)\n",
    "\n",
    "test_str = \"\"\"I am Park Jeong-tae. I live in Paju.\n",
    "I lived in Paju for 25 years. estadsffjkfad test\n",
    "Sample text for testing:\n",
    "abcdefghijklmestnopqrsAvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "0123456789 +-.,!@#$%^&*();\\/|<>\"'\n",
    "12345 -98.7 3.141 .6180 9,000 +42\"\"\"\n",
    "\n",
    "pattern = re.compile('[a-zA-Z0-9]+') # a부터 z까지, A부터 Z까지, 0부터 9까지 포함된 것\n",
    "pattern1 = re.compile('\\w+')\n",
    "c = pattern.findall(test_str)\n",
    "d = pattern1.findall(test_str)\n",
    "print(c)\n",
    "print(d)\n",
    "\n",
    "pattern = re.compile('[^a-z]+')  # a부터 z까지 포함되지 않는 것\n",
    "c = pattern.findall(test_str)\n",
    "print(c)\n",
    "\n",
    "pattern = re.compile('[^A-Z]+')  # A부터 Z까지 포함되지 않는 것\n",
    "c = pattern.findall(test_str)\n",
    "print(c)\n",
    "\n",
    "pattern = re.compile('t..t')  # t문자문자t 패턴\n",
    "pattern1 = re.compile('t...t')  # t문자문자문자t 패턴\n",
    "c = pattern.findall(test_str)\n",
    "d = pattern1.findall(test_str)\n",
    "print(c)\n",
    "print(d)\n",
    "\n",
    "pattern = re.compile('t?est\\w+')  # test나 est로 시작하는 문자열 뒤에 \\w가 있어야 됨\n",
    "pattern1 = re.compile('t?est\\w*')  # test나 est로 시작하는 문자열 뒤에 \\w가 없어도 됨\n",
    "c = pattern.findall(test_str)\n",
    "d = pattern1.findall(test_str)\n",
    "print(c)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-58 간단한 크롤러 만들기 1)\n",
    ">* 돔(dom)구조 파악 => Document Object Model의 약자로 문서를 구조화 시킨 것을 의미\n",
    ">* 여기서 문서란 html, xml\n",
    ">* 첫 페이지만 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[programming] [react] react 작업환경 설 react를 시작하기 전에 환경셋팅을 해보자 2017-05-20 06:29:05 +0000    |    박정태\n",
      "[programming] drag and drop을 이용하여 파일 업로드를 해보자 query의 외부 라이브러리가 아닌 drag, drop 이벤트를 활용하여 기능 구현해보기 2017-05-09 23:47:05 +0000    |    박정태\n",
      "[database] mysqldump를 이용하여 데이터 백업, 복원하기 mysqldump를 이용하여 디비 백업과 source를 이용하여 데이터 복원을 해보자 2017-05-04 05:33:05 +0000    |    박정태\n",
      "[database] mysql 원격접속하는 방법 mysql 디비설정, 유저설정을 통해 원격접속 2017-05-03 11:43:05 +0000    |    박정태\n",
      "[node.js] 파일 리더기 만들기 - 사용 모듈 정리, pdf와 hwp 구조 docx, hwp, pdf 파일 2017-05-01 06:02:05 +0000    |    박정태\n",
      "[node.js] 파일 리더기 만들기 - pdf를 html로 변환, docx를 pdf로 변환 pdf파일 html로 변경하기 2017-04-30 15:19:05 +0000    |    박정태\n",
      "[programming] git 원격 저장소 바꾸기 remote set-url을 이용하여 원격 저장소를 바꾸자 2017-04-25 13:09:05 +0000    |    박정태\n",
      "[programming] python working directory를 바꿔보자 working directory설정을 하여 경로 문제를 해결하자 2017-04-25 09:19:05 +0000    |    박정태\n",
      "[server] docker commends 도커의 명령어들을 간단하게 알아보기 2017-04-24 23:19:05 +0000    |    박정태\n",
      "[programming] python utc를 timestamp로 바꾸는 방법 python에서 utc를 timestamp로 바꾸는 방법 2017-04-24 13:19:05 +0000    |    박정태\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = 'https://pjt3591oo.github.io/'\n",
    "\n",
    "res = rq.get(base_url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "posts = soup.select('body main.page-content div.wrapper div.home div.p')\n",
    "\n",
    "for post in posts:\n",
    "    title = post.find('h3').text.strip()\n",
    "    descript = post.find('h4').text.strip()\n",
    "    author = post.find('span').text.strip()\n",
    "    print(title, descript, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-59 간단한 크롤러 만들기 2)\n",
    ">* 전체 수집을 할 수 있도록 수정\n",
    ">* 404 코드가 발생할 때까지 /page 숫자를 붙여서 url을 수정하여 계속 요청을 보냄\n",
    ">* 문제점은 돔제어를 반복적으로 작성하면 추후 웹 사이트 구조가 변경됐을 때 유지보수가 힘들어 짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[programming] ubuntu에 php 개발환경 셋팅 우분투에 php를 설치해보자 2017-04-23 09:19:05 +0000    |    박정태\n",
      "[server] azure-cli를 이용하여 azure 사용하기 대시보드를 사용하지 않고 azure-cli로 azure를 이용하기 2017-04-22 13:19:05 +0000    |    박정태\n",
      "[tools] ssh-keygen을 이용한 ssh 키 파일 생성 여러가지 인증 방법 중 ssh를 이용하기 위한 키 파일 생성방법 2017-04-21 04:14:05 +0000    |    박정태\n",
      "[programming] 제너레이터(generator)를 활용한 효율적인 코드작성 효율적인 코드 작성을 위한 generator 사용방법 입니다. 2017-04-19 13:58:05 +0000    |    박정태\n",
      "[node.js] Jade Template Engine을 활용한 효율적 관리  2017-04-15 01:39:05 +0000    |    박정태\n",
      "[tools] vim 각종 설정들로 부터 귀차니즘을 벗어나자  2017-04-12 23:26:05 +0000    |    박정태\n",
      "[node.js] sequelize - Migrations[번역]  2017-04-09 07:43:05 +0000    |    박정태\n",
      "[node.js] sequelize - Usage[번역]  2017-04-09 07:41:05 +0000    |    박정태\n",
      "[node.js] sequelize - Hooks[번역]  2017-04-09 07:38:05 +0000    |    박정태\n",
      "[node.js] sequelize - Querying[번역]  2017-04-09 07:37:05 +0000    |    박정태\n",
      "[node.js] sequelize - Working With Legacy Tables[번역]  2017-04-09 07:36:05 +0000    |    박정태\n",
      "[node.js] sequelize - Getting Started[번역]  2017-04-09 07:28:05 +0000    |    박정태\n",
      "[node.js] sequelize - Home[번역]  2017-04-09 07:00:05 +0000    |    박정태\n",
      "[machine-learning] Classification using Naive Bayes  2017-04-08 01:55:05 +0000    |    박정태\n",
      "[framework] Structure aiohttp Of python python 경량 서버 프레임 워크인 apihttp에 대한 boilerplate작성 및 설명입니다. 2017-04-08 01:30:05 +0000    |    박정태\n",
      "[framework] Structure Express Of Node  2017-04-08 01:22:05 +0000    |    박정태\n",
      "[programming] Javascript Asynchronous, synchronous and Promise  2017-04-08 01:08:05 +0000    |    박정태\n",
      "[database] RDBMS vs NoSQL vs InMemory Database에 대한 설명입니다. 2017-04-06 10:03:05 +0000    |    박정태\n",
      "[news] Django 1.11 Release Django1.11 버전 release note입니다 2017-04-05 23:03:05 +0000    |    박정태\n",
      "[programming] javascript arrow function과 array.prototype의 조합 javascript의 화살표 함수에 대한 글입니다. 2017-04-04 13:40:05 +0000    |    박정태\n",
      "[intro] Welcome to mung  2017-04-04 13:10:05 +0000    |    박정태\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = 'https://pjt3591oo.github.io/'\n",
    "page_path = 'page%d'\n",
    "page = 2\n",
    "\n",
    "res = rq.get(base_url)\n",
    "\n",
    "while True:\n",
    "    sub_path = page_path%(page)\n",
    "    page += 1\n",
    "    res = rq.get(base_url + sub_path)\n",
    "    \n",
    "    if (res.status_code !=200):\n",
    "        break\n",
    "    \n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    \n",
    "    posts = soup.select('body main.page-content div.wrapper div.home div.p')\n",
    "    \n",
    "    for post in posts:\n",
    "        title = post.find('h3').text.strip()\n",
    "        descript = post.find('h4').text.strip()\n",
    "        author = post.find('span').text.strip()\n",
    "        print(title, descript, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-60 간단한 웹크롤러 만들기 3)\n",
    ">* 돔을 조작하는 부분을 함수로 만들면 추후 사이트 구조가 바뀌더라도 함수 부분만 조정을 하면 되기 때문에 유지 보수가 훨씬 수월\n",
    ">* 돔 제어가 어떤 목적인지도 함수 이름을 통해 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[programming] [react] react 작업환경 설 react를 시작하기 전에 환경셋팅을 해보자 2017-05-20 06:29:05 +0000    |    박정태\n",
      "[programming] drag and drop을 이용하여 파일 업로드를 해보자 query의 외부 라이브러리가 아닌 drag, drop 이벤트를 활용하여 기능 구현해보기 2017-05-09 23:47:05 +0000    |    박정태\n",
      "[database] mysqldump를 이용하여 데이터 백업, 복원하기 mysqldump를 이용하여 디비 백업과 source를 이용하여 데이터 복원을 해보자 2017-05-04 05:33:05 +0000    |    박정태\n",
      "[database] mysql 원격접속하는 방법 mysql 디비설정, 유저설정을 통해 원격접속 2017-05-03 11:43:05 +0000    |    박정태\n",
      "[node.js] 파일 리더기 만들기 - 사용 모듈 정리, pdf와 hwp 구조 docx, hwp, pdf 파일 2017-05-01 06:02:05 +0000    |    박정태\n",
      "[node.js] 파일 리더기 만들기 - pdf를 html로 변환, docx를 pdf로 변환 pdf파일 html로 변경하기 2017-04-30 15:19:05 +0000    |    박정태\n",
      "[programming] git 원격 저장소 바꾸기 remote set-url을 이용하여 원격 저장소를 바꾸자 2017-04-25 13:09:05 +0000    |    박정태\n",
      "[programming] python working directory를 바꿔보자 working directory설정을 하여 경로 문제를 해결하자 2017-04-25 09:19:05 +0000    |    박정태\n",
      "[server] docker commends 도커의 명령어들을 간단하게 알아보기 2017-04-24 23:19:05 +0000    |    박정태\n",
      "[programming] python utc를 timestamp로 바꾸는 방법 python에서 utc를 timestamp로 바꾸는 방법 2017-04-24 13:19:05 +0000    |    박정태\n",
      "[programming] ubuntu에 php 개발환경 셋팅 우분투에 php를 설치해보자 2017-04-23 09:19:05 +0000    |    박정태\n",
      "[server] azure-cli를 이용하여 azure 사용하기 대시보드를 사용하지 않고 azure-cli로 azure를 이용하기 2017-04-22 13:19:05 +0000    |    박정태\n",
      "[tools] ssh-keygen을 이용한 ssh 키 파일 생성 여러가지 인증 방법 중 ssh를 이용하기 위한 키 파일 생성방법 2017-04-21 04:14:05 +0000    |    박정태\n",
      "[programming] 제너레이터(generator)를 활용한 효율적인 코드작성 효율적인 코드 작성을 위한 generator 사용방법 입니다. 2017-04-19 13:58:05 +0000    |    박정태\n",
      "[node.js] Jade Template Engine을 활용한 효율적 관리  2017-04-15 01:39:05 +0000    |    박정태\n",
      "[tools] vim 각종 설정들로 부터 귀차니즘을 벗어나자  2017-04-12 23:26:05 +0000    |    박정태\n",
      "[node.js] sequelize - Migrations[번역]  2017-04-09 07:43:05 +0000    |    박정태\n",
      "[node.js] sequelize - Usage[번역]  2017-04-09 07:41:05 +0000    |    박정태\n",
      "[node.js] sequelize - Hooks[번역]  2017-04-09 07:38:05 +0000    |    박정태\n",
      "[node.js] sequelize - Querying[번역]  2017-04-09 07:37:05 +0000    |    박정태\n",
      "[node.js] sequelize - Working With Legacy Tables[번역]  2017-04-09 07:36:05 +0000    |    박정태\n",
      "[node.js] sequelize - Getting Started[번역]  2017-04-09 07:28:05 +0000    |    박정태\n",
      "[node.js] sequelize - Home[번역]  2017-04-09 07:00:05 +0000    |    박정태\n",
      "[machine-learning] Classification using Naive Bayes  2017-04-08 01:55:05 +0000    |    박정태\n",
      "[framework] Structure aiohttp Of python python 경량 서버 프레임 워크인 apihttp에 대한 boilerplate작성 및 설명입니다. 2017-04-08 01:30:05 +0000    |    박정태\n",
      "[framework] Structure Express Of Node  2017-04-08 01:22:05 +0000    |    박정태\n",
      "[programming] Javascript Asynchronous, synchronous and Promise  2017-04-08 01:08:05 +0000    |    박정태\n",
      "[database] RDBMS vs NoSQL vs InMemory Database에 대한 설명입니다. 2017-04-06 10:03:05 +0000    |    박정태\n",
      "[news] Django 1.11 Release Django1.11 버전 release note입니다 2017-04-05 23:03:05 +0000    |    박정태\n",
      "[programming] javascript arrow function과 array.prototype의 조합 javascript의 화살표 함수에 대한 글입니다. 2017-04-04 13:40:05 +0000    |    박정태\n",
      "[intro] Welcome to mung  2017-04-04 13:10:05 +0000    |    박정태\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_posts(soup):\n",
    "    return soup.select('body main.page-content div.wrapper div.home div.p')\n",
    "\n",
    "def data_parse(posts):\n",
    "    for post in posts:\n",
    "        title = post.find('h3').text.strip()\n",
    "        descript = post.find('h4').text.strip()\n",
    "        author = post.find('span').text.strip()\n",
    "        print(title, descript, author)\n",
    "\n",
    "base_url = 'https://pjt3591oo.github.io/'\n",
    "page_path = 'page%d'\n",
    "page = 2\n",
    "\n",
    "res = rq.get(base_url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "posts = get_posts(soup)\n",
    "data_parse(posts)\n",
    "\n",
    "while True:\n",
    "    sub_path = page_path%(page)\n",
    "    page += 1\n",
    "    res = rq.get(base_url + sub_path)\n",
    "    \n",
    "    if (res.status_code !=200):\n",
    "        break\n",
    "    \n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    posts = get_posts(soup)\n",
    "    \n",
    "    data_parse(posts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
